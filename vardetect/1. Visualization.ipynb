{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os, warnings, tensorflow as tf\n",
    "from utils.model import * \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we begin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a preliminary public code repository to the paper \"Stateful Detection of Model Extraction Attacks\".\n",
    "\n",
    "Our code base borrows from the following other repositories:\n",
    "\n",
    "* **StealML** of Tramer _et al._ [1] - [https://github.com/ftramer/Steal-ML/](https://github.com/ftramer/Steal-ML/)\n",
    "* **ActiveThief** of Pal _et al._ [2] - [https://bitbucket.org/iiscseal/activethief/](https://bitbucket.org/iiscseal/activethief/)\n",
    "\n",
    "The AdvPD attacks in Papernot _et al._ [3] are reimplemented by us.\n",
    "\n",
    "The Fashion-MNIST dataset is courtesy Han Xiao _et al._ [4], made available on their [Github repository](https://github.com/zalandoresearch/fashion-mnist) under a MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License (MIT) Copyright ©\n",
    "\n",
    "1. **Fashion MNIST:** [2017] Zalando SE, https://tech.zalando.com\n",
    "\n",
    "2. **ActiveThief:** 2019 Soham Pal, Yash Gupta, Aditya Shukla, Aditya Kanade, Shirish Shevade, Vinod Ganapathy. Indian Institute of Science.\n",
    "\n",
    "    THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.fashionmnist_dsl import FashionMNISTDSL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partition classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data\n",
      "datasets/fashionmnist/t10k-images-idx3-ubyte\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "partition_seed = 1337\n",
    "\n",
    "np.random.seed(partition_seed)\n",
    "\n",
    "train_dsl = FashionMNISTDSL(batch_size=100, mode='test', normalize_channels=False, shuffle_each_epoch=False, seed=666)\n",
    "chosen_classes = list(np.random.choice(np.arange(train_dsl.num_classes), train_dsl.num_classes//2, False))\n",
    "remaining_classes = list(set(list(np.arange(train_dsl.num_classes))) - set(chosen_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 3, 0, 4, 5]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 2, 9, 7]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load confidential dataset $\\mathcal{D}_C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DSL only for classes 6 3 0 4 5\n",
      "Loading train data\n",
      "datasets/fashionmnist/train-images-idx3-ubyte\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Your last batch only has 25 samples!\n",
      "WARNING:root:Your last batch only has 75 samples!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DSL only for classes 6 3 0 4 5\n",
      "Loading val data\n",
      "datasets/fashionmnist/train-images-idx3-ubyte\n",
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "processing...\n"
     ]
    }
   ],
   "source": [
    "train_dsl = FashionMNISTDSL(batch_size = 100, mode='train', normalize_channels=False, shuffle_each_epoch=False, seed=666, keep_class=chosen_classes)\n",
    "val_dsl   = FashionMNISTDSL(batch_size = 100, mode='val', normalize_channels=False, shuffle_each_epoch=False, seed=666, keep_class=chosen_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load benign users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DSL only for classes 6 3 0 4 5\n",
      "Loading test data\n",
      "datasets/fashionmnist/t10k-images-idx3-ubyte\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "processing...\n"
     ]
    }
   ],
   "source": [
    "PD_test_dsl  = FashionMNISTDSL(batch_size = 100, mode='test', normalize_channels=False, shuffle_each_epoch=False, seed=666, keep_class=chosen_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DSL only for classes 8 1 2 9 7\n",
      "Loading test data\n",
      "datasets/fashionmnist/t10k-images-idx3-ubyte\n",
      "(10000, 28, 28, 1)\n",
      "(10000,)\n",
      "processing...\n"
     ]
    }
   ],
   "source": [
    "AltPD_test_dsl  = FashionMNISTDSL(batch_size = 100, mode='test', normalize_channels=False, shuffle_each_epoch=False, seed=666, keep_class=remaining_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain dataset parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, channels = train_dsl.get_sample_shape()\n",
    "\n",
    "is_multilabel = train_dsl.is_multilabel()\n",
    "num_classes = train_dsl.get_num_classes()\n",
    "num_batches = train_dsl.get_num_batches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load attacker datasets $\\mathcal{D}_A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syn-Uniform Retraining (Tramer _et al._ [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dsl.uniform_dsl import UniformDSL\n",
    "\n",
    "sample_shape = (width, height, channels)\n",
    "uniform_dsl = UniformDSL(batch_size=100, mode='train', shape=sample_shape, sample_limit=1000, seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ImageNet samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train data\n",
      "datasets/Imagenet64/train_data_batch_1.npy\n"
     ]
    }
   ],
   "source": [
    "from dsl.imagenet_dsl import ImagenetDSL\n",
    "\n",
    "resize = (width, height)\n",
    "img_noise_train_dsl = ImagenetDSL(batch_size=100, mode='train', resize=resize, normalize_channels=True, num_to_keep=1000, start_batch=1, end_batch=1, seed=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from models.deepcnn import DeepCNN\n",
    "from models.vae import NewHSVNVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cfg import cfg, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"vae_2/Decoder/conv2d_transpose/LeakyRelu:0\", shape=(?, 2, 2, 256), dtype=float32)\n",
      "Tensor(\"vae_2/Decoder/conv2d_transpose_1/LeakyRelu:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
      "Tensor(\"vae_2/Decoder/conv2d_transpose_2/LeakyRelu:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
      "Tensor(\"vae_2/Decoder/conv2d_transpose_3/LeakyRelu:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
      "Tensor(\"vae_2/Decoder/conv2d_transpose_4/Sigmoid:0\", shape=(?, 28, 28, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"vae\", reuse=tf.AUTO_REUSE):\n",
    "    vae = NewHSVNVAE(\n",
    "            batch_size=cfg.batch_size,\n",
    "            height=height, width=width,\n",
    "            channels=channels,\n",
    "            num_classes=2,\n",
    "            is_training=False,\n",
    "            z_size=32,\n",
    "            random_draws=1,\n",
    "            noise_mean=5.0\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-1337/model_epoch_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from modeldir/fashionmnist-1337/model_epoch_100\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, 'modeldir/fashionmnist-1337/model_epoch_100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we demonstrate the outlier dataset $\\mathcal{D}_O$ generation procedure. Samples are shown in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_dsl = copy.deepcopy(train_dsl)\n",
    "num_train_samples = outlier_dsl.data.shape[0]\n",
    "\n",
    "locs = np.random.uniform(0.0, 1.0, size=num_train_samples)\n",
    "noise_generated = np.concatenate([[np.random.normal(loc=loc, scale=0.5, size=outlier_dsl.data.shape[1:]) for loc in locs]])\n",
    "vnoise   = np.random.uniform(low=0.2, high=0.3, size=num_train_samples )\n",
    "vnoise   = vnoise.reshape(-1, 1, 1, 1)\n",
    "\n",
    "outlier_dsl.data = np.clip(vnoise * noise_generated + (1-vnoise) * outlier_dsl.data, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AdvPD samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "advpd_dsl = copy.deepcopy(train_dsl)\n",
    "advpd_dsl.data = np.load('datasets/AdvPD.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Previews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we show the representation in latent space, let us take a look at the original dataset samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidential dataset $\\mathcal{D}_C$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'train_dsl' if it doesn't exist\n",
    "folder_name = 'train_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(train_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'train_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'train_dsl' if it doesn't exist\n",
    "folder_name = 'val_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(val_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'train_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PD Benign User samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'PD_test_dsl' if it doesn't exist\n",
    "folder_name = 'PD_test_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(PD_test_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'PD_test_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AltPD Benign User samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'AltPD_test_dsl' if it doesn't exist\n",
    "folder_name = 'AltPD_test_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(AltPD_test_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'AltPD_test_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier dataset $\\mathcal{D}_O$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'outlier_dsl' if it doesn't exist\n",
    "folder_name = 'outlier_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(outlier_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'outlier_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syn-Uniform Retraining attacker dataset $\\mathcal{D}_A$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'uniform_dsl' if it doesn't exist\n",
    "folder_name = 'uniform_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(uniform_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'uniform_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdvPD-JSMA attacker dataset $\\mathcal{D}_A$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'advpd_dsl' if it doesn't exist\n",
    "folder_name = 'advpd_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(advpd_dsl.data[150:][i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'advpd_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NPD-ActiveThief attacker dataset $\\mathcal{D}_A$ samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a folder named 'img_noise_train_dsl' if it doesn't exist\n",
    "folder_name = 'img_noise_train_dsl'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for i in range(1, 100 * 10 + 1):\n",
    "    fig = plt.figure(figsize=(1, 1))  # Create a new figure for each image\n",
    "    img = np.random.randint(10, size=(10, 10))\n",
    "    plt.imshow(img_noise_train_dsl.data[i - 1].squeeze(-1), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(folder_name, 'image_{}.png'.format(i)), bbox_inches='tight', pad_inches=0)  # Save each image in the 'img_noise_train_dsl' folder\n",
    "    plt.close()  # Close the current figure to release memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let us take a look at the latent representations for various datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dsl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_train_zs = sample_z(vae, train_dsl, sess)\n",
    "outlier_zs    = sample_z(vae, outlier_dsl, sess)\n",
    "uniform_zs    = sample_z(vae, uniform_dsl, sess)\n",
    "advpd_zs      = sample_z(vae, advpd_dsl, sess)\n",
    "img_noise_zs  = sample_z(vae, img_noise_train_dsl, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_zs = sample_z(vae, PD_test_dsl, sess)\n",
    "altpd_zs = sample_z(vae, AltPD_test_dsl, sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = [ 'Confidential', 'Outlier' ]\n",
    "plot_pca([true_train_zs, outlier_zs], labels=labels, num_samples=1000, markers=['o', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = [ 'Confidential', 'Syn' ]\n",
    "plot_pca([true_train_zs, uniform_zs], labels=labels, num_samples=1000, markers=['o', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = [ 'Confidential', 'AdvPD seed', 'AdvPD' ]\n",
    "plot_pca([true_train_zs, advpd_zs[:150], advpd_zs[150:]], labels=labels, num_samples=1000, markers=['o', 'x', 'x'], facecolors=[False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = ['Confidential', 'NPD']\n",
    "plot_pca([true_train_zs, img_noise_zs], labels=labels, num_samples=1000, markers=['o', 'x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = [ 'Confidential', 'Outlier', 'AltPD' ]\n",
    "plot_pca([true_train_zs, outlier_zs, altpd_zs], labels=labels, num_samples=1000, markers=['o', 'x', 'x'], facecolors=[False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels  = [ 'Confidential', 'Outlier', 'PD' ]\n",
    "plot_pca([true_train_zs, outlier_zs, pd_zs], labels=labels, num_samples=1000, markers=['o', 'x', 'x'], facecolors=[False, True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Tramer, F.; Zhang, F.; Juels, A.; Reiter, M. K.; and Ristenpart, T. 2016.  \n",
    "Stealing Machine Learning Models via Prediction APIs.  \n",
    "In _USENIX Security 16_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] Pal, S.; Gupta, Y.; Shukla, A.; Kanade, A.; Shevade, S. K.; and Ganapathy, V. 2020.  \n",
    "ActiveThief: Model Extraction Using Active Learning and Unannotated Public Data.  \n",
    "In _Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI’20. AAAI Press_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] Papernot, N.; McDaniel, P.; Goodfellow, I.; Jha, S.; Celik, Z. B.; and Swami, A. 2017.  \n",
    "Practical Black-Box Attacks against Machine Learning.  \n",
    "In _Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security, ASIA CCS '17_. ACM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] Xiao, H.; Rasul, K.; and Vollgraf, R. 2017.  \n",
    "Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms.  \n",
    "_CoRR_ abs/1708.07747. URL http://arxiv.org/abs/1708.07747."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python var_kernal",
   "language": "python",
   "name": "var"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
